{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "qfD5CuZxI_cN",
        "ff-mshaDJQnn"
      ]
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 13730092,
          "sourceType": "datasetVersion",
          "datasetId": 8735525
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM TRAINING FROM SCRATCH"
      ],
      "metadata": {
        "id": "QDYHAVefIhtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "This notebook implements a multi-label emotion classification pipeline using a custom Bi-directional LSTM architecture trained from scratch. It utilizes a SentencePiece (BPE) tokenizer trained directly on the corpus to encode text into 256-token sequences. The training process optimizes a BCEWithLogitsLoss objective across five emotion labels using AdamW and Cosine Annealing, with experiment tracking provided by W&B and model saving determined by the best validation Macro-F1 score."
      ],
      "metadata": {
        "id": "U90uPpelI9Rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "qfD5CuZxI_cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "Fj05QsBtv4B6",
        "outputId": "eea2f110-4ebc-406d-8762-83e279bd4c82",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T16:17:28.388802Z",
          "iopub.execute_input": "2025-11-28T16:17:28.388986Z",
          "iopub.status.idle": "2025-11-28T16:17:37.865366Z",
          "shell.execute_reply.started": "2025-11-28T16:17:28.388968Z",
          "shell.execute_reply": "2025-11-28T16:17:37.864621Z"
        },
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.3.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (25.0)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.5.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (6.33.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.12.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.3)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.5)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.2)\nRequirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.15.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyarrow-22.0.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import os\n",
        "import wandb\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "wandb.login(key=\"16a767377715590d2d5fe6351174577f96db6dc6\")"
      ],
      "metadata": {
        "id": "GMQH01kLv8nc",
        "outputId": "6f9d3951-ed65-4edf-8ce5-899b513a18cb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T16:19:07.629122Z",
          "iopub.execute_input": "2025-11-28T16:19:07.629463Z",
          "iopub.status.idle": "2025-11-28T16:19:53.189915Z",
          "shell.execute_reply.started": "2025-11-28T16:19:07.629424Z",
          "shell.execute_reply": "2025-11-28T16:19:53.189219Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-11-28 16:19:23.010698: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764346763.192704      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764346763.247451      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables"
      ],
      "metadata": {
        "id": "ff-mshaDJQnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "MAX_LEN = 256\n",
        "BATCH = 64\n",
        "EPOCHS = 10\n",
        "LR = 2e-3\n",
        "LABEL_COLS = [\"anger\",\"fear\",\"joy\",\"sadness\",\"surprise\"]\n",
        "\n",
        "#set random seed\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T16:46:12.540876Z",
          "iopub.execute_input": "2025-11-28T16:46:12.541474Z",
          "iopub.status.idle": "2025-11-28T16:46:12.550345Z",
          "shell.execute_reply.started": "2025-11-28T16:46:12.541449Z",
          "shell.execute_reply": "2025-11-28T16:46:12.549478Z"
        },
        "id": "h_ZusQXFIfet",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "747226bc-0a64-4918-8811-ebc39d5c2173"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'random' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-823572034.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-823572034.py\u001b[0m in \u001b[0;36mset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Data"
      ],
      "metadata": {
        "id": "Dj-QEfIiJxNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/kaggle/input/dlgenai/augmented_train.csv\")\n",
        "\n",
        "test_df  = pd.read_csv(\"/kaggle/input/dlgenai/test_clean.csv\")\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "8JfXNLd3KWCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exporting text from our df to a file, replacing newlines with spaces to prepare a clean corpus. It then trains a SentencePiece Byte-Pair Encoding (BPE) tokenizer on that file with a vocabulary size of 28,000.**"
      ],
      "metadata": {
        "id": "Y1cKTfBh0ucx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def clean_text(text):\n",
        "    # Convert to string\n",
        "    text = str(text)\n",
        "    # Normalize unicode\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    # Replace newlines/tabs with space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text\n",
        "\n",
        "train_df[\"text_clean\"] = train_df[\"text\"].apply(clean_text)\n",
        "test_df[\"text_clean\"] = test_df[\"text\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "ipsJsJyooQXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"all_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for t in train_df[\"text\"]:\n",
        "        f.write(str(t).replace(\"\\n\", \" \") + \"\\n\")\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    input=\"all_text.txt\",\n",
        "    model_prefix=\"bpe_tokenizer\",\n",
        "    vocab_size=28000,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=1.0,\n",
        "    max_sentence_length=99999\n",
        ")"
      ],
      "metadata": {
        "id": "cSSQ8-eJKZdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"bpe_tokenizer.model\")"
      ],
      "metadata": {
        "id": "J0VQFWM0KdWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text, max_len=MAX_LEN):\n",
        "    ids = sp.encode(text, out_type=int)\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0] * (max_len - len(ids))\n",
        "    else:\n",
        "        ids = ids[:max_len]\n",
        "    return ids"
      ],
      "metadata": {
        "id": "pQNb887WtuXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(df, is_test=False):\n",
        "    data = []\n",
        "    for _, row in df.iterrows():\n",
        "        ids = encode(str(row[\"text\"]))\n",
        "        if is_test:\n",
        "            labels = torch.zeros(len(LABEL_COLS))\n",
        "        else:\n",
        "            labels = torch.tensor([row[c] for c in LABEL_COLS], dtype=torch.float)\n",
        "\n",
        "        data.append({\n",
        "            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"labels\": labels\n",
        "        })\n",
        "    return data\n",
        "\n",
        "train_ds = preprocess_dataset(train_df)\n",
        "val_ds   = preprocess_dataset(val_df)\n",
        "test_ds  = preprocess_dataset(test_df, is_test=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH)"
      ],
      "metadata": {
        "id": "T8C5DjI3t0No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL"
      ],
      "metadata": {
        "id": "pqoSjQI_t2wY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining a bidirectional LSTM to process input embeddings into a 128-dimensional hidden state. It extracts the features from the final time step, stabilizes them with Batch Normalization and Dropout, and maps them to 5 classes**"
      ],
      "metadata": {
        "id": "NCcTGn7b5IpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMEmotion(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_labels=5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            embed_dim,\n",
        "            hidden_dim,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.bn = nn.BatchNorm1d(hidden_dim * 2)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.embedding(input_ids)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        cls = lstm_out[:, -1, :]\n",
        "        cls = self.bn(cls)\n",
        "        cls = self.dropout(cls)\n",
        "        return self.fc(cls)"
      ],
      "metadata": {
        "id": "2nP0GKZ-t4Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = LSTMEmotion(sp.get_piece_size()).to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "nC9tfm9JuEOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRAINING"
      ],
      "metadata": {
        "id": "HIwKpPsnydxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**full training loop with gradient clipping and evaluating the model using the Macro F1 score on the validation set and logging training metrics to WandB and saving model whenever the validation F1 improves**"
      ],
      "metadata": {
        "id": "CB25N-sw5kYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"23f3001910-t32025\",\n",
        "    name=\"lstm\",\n",
        "    config={\n",
        "        \"seed\": SEED,\n",
        "        \"lr\": LR,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"batch\": BATCH,\n",
        "        \"max_len\": MAX_LEN,\n",
        "        \"model\": \"LSTM + BPE\",\n",
        "        \"scheduler\": \"CosineAnnealingLR\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "OTLblAXFuF5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_f1 = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        lbl = batch[\"labels\"].to(device)\n",
        "\n",
        "        logits = model(ids)\n",
        "        loss = loss_fn(logits, lbl)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # VALIDATION\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            lbl = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "            logits = model(ids).cpu()\n",
        "            probs = torch.sigmoid(logits).numpy()\n",
        "            preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "            all_labels.append(lbl)\n",
        "            all_preds.append(preds)\n",
        "\n",
        "    all_labels = np.vstack(all_labels)\n",
        "    all_preds = np.vstack(all_preds)\n",
        "\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "    lr_now = scheduler.get_last_lr()[0]\n",
        "\n",
        "    # WANDB LOG\n",
        "    wandb.log({\n",
        "        \"train_loss\": total_loss / len(train_loader),\n",
        "        \"val_f1\": macro_f1,\n",
        "        \"lr\": lr_now\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss={total_loss/len(train_loader):.4f} | F1={macro_f1:.4f}\")\n",
        "\n",
        "\n",
        "    if macro_f1 > best_f1:\n",
        "        best_f1 = macro_f1\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        wandb.save(\"best_model.pth\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T16:50:54.437348Z",
          "iopub.execute_input": "2025-11-28T16:50:54.437695Z",
          "iopub.status.idle": "2025-11-28T16:51:48.382953Z",
          "shell.execute_reply.started": "2025-11-28T16:50:54.437664Z",
          "shell.execute_reply": "2025-11-28T16:51:48.382163Z"
        },
        "id": "wGWituXJIfez",
        "outputId": "77b424d6-5f64-45a0-c1cd-5b34056acf5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training BPE tokenizer...\nTokenizer vocab size: 28000\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Finishing previous runs because reinit is set to 'default'."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>█▇▇▆▅▃▂▂▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▃▆▅█▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0</td></tr><tr><td>train_loss</td><td>0.64269</td></tr><tr><td>val_f1</td><td>0.14419</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">lstm</strong> at: <a href='https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/t91r37nc' target=\"_blank\">https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/t91r37nc</a><br> View project at: <a href='https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025' target=\"_blank\">https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20251128_164624-t91r37nc/logs</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.21.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20251128_165059-ut8jgvp0</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/ut8jgvp0' target=\"_blank\">lstm</a></strong> to <a href='https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025' target=\"_blank\">https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/ut8jgvp0' target=\"_blank\">https://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/ut8jgvp0</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10 | Loss=0.6459 | F1=0.3448\nEpoch 2/10 | Loss=0.6433 | F1=0.2501\nEpoch 3/10 | Loss=0.6430 | F1=0.0947\nEpoch 4/10 | Loss=0.6429 | F1=0.3409\nEpoch 5/10 | Loss=0.6429 | F1=0.3942\nEpoch 6/10 | Loss=0.6429 | F1=0.1442\nEpoch 7/10 | Loss=0.6428 | F1=0.1442\nEpoch 8/10 | Loss=0.6428 | F1=0.0000\nEpoch 9/10 | Loss=0.6428 | F1=0.1442\nEpoch 10/10 | Loss=0.6427 | F1=0.1442\nTraining complete. Best F1: 0.39416478590409926\n\nRunning inference on test.csv...\nSaved test_predictions.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##INFERENCE"
      ],
      "metadata": {
        "id": "U-SHn79xuWuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#INFERENCE\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "test_preds = []\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        ids = batch[\"input_ids\"].to(device)\n",
        "        logits = model(ids)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()\n",
        "        preds = (probs >= threshold).astype(int)  # convert to 0/1\n",
        "        test_preds.append(preds)\n",
        "\n",
        "test_preds = np.vstack(test_preds)\n",
        "\n",
        "# Attach predictions\n",
        "for i, col in enumerate(LABEL_COLS):\n",
        "    test_df[col] = test_preds[:, i]"
      ],
      "metadata": {
        "id": "9aXWmI9-uYQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save predictions\n",
        "test_df = test_df[['id','anger','fear', 'joy', 'sadness','surprise']]\n",
        "test_df.to_csv(\"test_predictions.csv\", index=False)\n",
        "wandb.save(\"test_predictions.csv\")\n",
        "print(\"Saved test_predictions.csv\")"
      ],
      "metadata": {
        "id": "boc1Sx6oz0y_",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-28T16:53:03.336154Z",
          "iopub.execute_input": "2025-11-28T16:53:03.336855Z",
          "iopub.status.idle": "2025-11-28T16:53:03.348491Z",
          "shell.execute_reply.started": "2025-11-28T16:53:03.336831Z",
          "shell.execute_reply": "2025-11-28T16:53:03.347830Z"
        },
        "outputId": "b7b2fb9c-2edb-4935-d7d2-ec33d0486e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Saved test_predictions.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgc-cMZ10Ev1",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}