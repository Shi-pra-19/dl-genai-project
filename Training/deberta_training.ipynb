{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shi-pra-19/dl-genai-project/blob/main/deberta_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DeBERTA TRAINING"
      ],
      "metadata": {
        "id": "Zz9fHp1H-Mdy"
      },
      "id": "Zz9fHp1H-Mdy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Overview\n",
        "\n",
        "After training a single DeBERTa-Large baseline model for 7 epochs,resulting in 0.870 score on leaderboard, we extend the setup by training three separate models with different random seeds (42, 2025, 123) to improve stability and generalization. The training uses a long sequence length (MAX_LEN = 512), gradient accumulation for an effective larger batch size, and a 7-epoch schedule with a cosine LR scheduler. To better handle class imbalance, we replace the default BCE loss with Focal Loss (Œ± = 0.25, Œ≥ = 2.0) through a custom Trainer. Each model is trained using the same hyperparameters and tokenization settings, and the best results per epoch are logged via Weights & Biases. After training, we compute optimal per-label thresholds using validation predictions, and then create an ensemble by averaging model probabilities across all seeds. Finally, the ensemble is used to generate test predictions, apply tuned thresholds, and create the final submission CSV along with saved thresholds for reproducibility."
      ],
      "metadata": {
        "id": "xPhiKxSK-O20"
      },
      "id": "xPhiKxSK-O20"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTS"
      ],
      "metadata": {
        "id": "h4nYAPKE-mbO"
      },
      "id": "h4nYAPKE-mbO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cf0ebc6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:47:36.221033Z",
          "iopub.status.busy": "2025-11-28T12:47:36.220762Z",
          "iopub.status.idle": "2025-11-28T12:47:44.092418Z",
          "shell.execute_reply": "2025-11-28T12:47:44.091469Z"
        },
        "id": "0cf0ebc6",
        "outputId": "7ce219aa-6422-4f6b-ffce-7078e1763f22",
        "papermill": {
          "duration": 7.884275,
          "end_time": "2025-11-28T12:47:44.093850",
          "exception": false,
          "start_time": "2025-11-28T12:47:36.209575",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\r\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\r\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\r\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.3.0)\r\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\r\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (25.0)\r\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.5.0)\r\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (6.33.0)\r\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.12.4)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.3)\r\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.5)\r\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.33.2)\r\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.15.0)\r\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\r\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\r\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\r\n",
            "  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\r\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\r\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\r\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\r\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\r\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\r\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\r\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\r\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\r\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\r\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\r\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\r\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\r\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\r\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\r\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\r\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\r\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\r\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.41.5)\r\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.2)\r\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\r\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\r\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\r\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\r\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\r\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\r\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\r\n",
            "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\r\n",
            "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\r\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\r\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
            "Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\r\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: pyarrow\r\n",
            "  Attempting uninstall: pyarrow\r\n",
            "    Found existing installation: pyarrow 19.0.1\r\n",
            "    Uninstalling pyarrow-19.0.1:\r\n",
            "      Successfully uninstalled pyarrow-19.0.1\r\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
            "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
            "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
            "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
            "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0mSuccessfully installed pyarrow-22.0.0\r\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a891fcd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:47:44.115717Z",
          "iopub.status.busy": "2025-11-28T12:47:44.115064Z",
          "iopub.status.idle": "2025-11-28T12:48:21.704089Z",
          "shell.execute_reply": "2025-11-28T12:48:21.703303Z"
        },
        "id": "5a891fcd",
        "papermill": {
          "duration": 37.601242,
          "end_time": "2025-11-28T12:48:21.705585",
          "exception": false,
          "start_time": "2025-11-28T12:47:44.104343",
          "status": "completed"
        },
        "tags": [],
        "outputId": "aee48a7f-7a9f-46f6-920a-896e639b72ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-28 12:47:59.042589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764334079.238023      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764334079.293472      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from torch import nn\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from datasets import Dataset, DatasetDict\n",
        "import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables"
      ],
      "metadata": {
        "id": "FJOOYj_k-rQr"
      },
      "id": "FJOOYj_k-rQr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "900404cd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:21.727344Z",
          "iopub.status.busy": "2025-11-28T12:48:21.726704Z",
          "iopub.status.idle": "2025-11-28T12:48:22.152904Z",
          "shell.execute_reply": "2025-11-28T12:48:22.152175Z"
        },
        "id": "900404cd",
        "outputId": "0b6ea483-96cd-40bd-fc5c-575e1df501fd",
        "papermill": {
          "duration": 0.438064,
          "end_time": "2025-11-28T12:48:22.154085",
          "exception": false,
          "start_time": "2025-11-28T12:48:21.716021",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key='16a767377715590d2d5fe6351174577f96db6dc6')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfe2d11e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.176077Z",
          "iopub.status.busy": "2025-11-28T12:48:22.175829Z",
          "iopub.status.idle": "2025-11-28T12:48:22.238744Z",
          "shell.execute_reply": "2025-11-28T12:48:22.238167Z"
        },
        "id": "cfe2d11e",
        "papermill": {
          "duration": 0.074885,
          "end_time": "2025-11-28T12:48:22.239896",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.165011",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/kaggle/input/dlgenai/augmented_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe05e31c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.262072Z",
          "iopub.status.busy": "2025-11-28T12:48:22.261579Z",
          "iopub.status.idle": "2025-11-28T12:48:22.265590Z",
          "shell.execute_reply": "2025-11-28T12:48:22.265054Z"
        },
        "id": "fe05e31c",
        "papermill": {
          "duration": 0.01616,
          "end_time": "2025-11-28T12:48:22.266635",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.250475",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "GRADIENT_ACCUMULATION_STEPS = 4\n",
        "EPOCHS = 7\n",
        "LEARNING_RATE = 2e-5\n",
        "DEBERTA_MODEL = \"microsoft/deberta-v3-large\"\n",
        "NUM_LABELS = 5\n",
        "LABEL_COLS = [\"anger\", \"joy\", \"fear\", \"surprise\", \"sadness\"]\n",
        "SEEDS = [42, 2025, 123]\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d3c54d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.288091Z",
          "iopub.status.busy": "2025-11-28T12:48:22.287705Z",
          "iopub.status.idle": "2025-11-28T12:48:22.291219Z",
          "shell.execute_reply": "2025-11-28T12:48:22.290688Z"
        },
        "id": "31d3c54d",
        "papermill": {
          "duration": 0.015245,
          "end_time": "2025-11-28T12:48:22.292268",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.277023",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUSTOM LOSS"
      ],
      "metadata": {
        "id": "-UaO1XbR-uhk"
      },
      "id": "-UaO1XbR-uhk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Focal Loss module that down-weights easy examples and focuses training on harder, misclassified samples using Œ± = 0.25 and Œ≥ = 2.0. It then integrates this loss into a CustomTrainer by overriding compute_loss, replacing the default BCE loss with Focal Loss for more robust multi-label emotion classification.**\n",
        "\n",
        "**Focal Loss is used to handle class imbalance by reducing the contribution of easy negatives and pushing the model to learn harder, minority-class examples more effectively. Integrating it into the CustomTrainer helps improve recall and overall F1 scores for under-represented emotion labels.**"
      ],
      "metadata": {
        "id": "-Mi76RLK-zUI"
      },
      "id": "-Mi76RLK-zUI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b34f91c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.313504Z",
          "iopub.status.busy": "2025-11-28T12:48:22.313071Z",
          "iopub.status.idle": "2025-11-28T12:48:22.317055Z",
          "shell.execute_reply": "2025-11-28T12:48:22.316544Z"
        },
        "id": "b34f91c9",
        "papermill": {
          "duration": 0.015567,
          "end_time": "2025-11-28T12:48:22.318024",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.302457",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "        return F_loss.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9b6480",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.338911Z",
          "iopub.status.busy": "2025-11-28T12:48:22.338715Z",
          "iopub.status.idle": "2025-11-28T12:48:22.342646Z",
          "shell.execute_reply": "2025-11-28T12:48:22.342110Z"
        },
        "id": "ef9b6480",
        "papermill": {
          "duration": 0.015508,
          "end_time": "2025-11-28T12:48:22.343611",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.328103",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "        loss = loss_fct(logits, labels.float())\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d9922c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:29.143446Z",
          "iopub.status.busy": "2025-11-28T12:48:29.143231Z",
          "iopub.status.idle": "2025-11-28T12:48:29.147456Z",
          "shell.execute_reply": "2025-11-28T12:48:29.146925Z"
        },
        "id": "5d9922c1",
        "papermill": {
          "duration": 0.016941,
          "end_time": "2025-11-28T12:48:29.148537",
          "exception": false,
          "start_time": "2025-11-28T12:48:29.131596",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = (torch.sigmoid(torch.tensor(logits)) >= 0.5).int().numpy()\n",
        "    labels = labels.astype(int)\n",
        "    macro_f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
        "    per_label_f1 = f1_score(labels, preds, average=None, zero_division=0)\n",
        "    result = {\"macro_f1\": macro_f1}\n",
        "    for lbl, score in zip(LABEL_COLS, per_label_f1):\n",
        "        result[f\"f1_{lbl}\"] = score\n",
        "    wandb.log(result)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimal Thresholds\n",
        "\n",
        "**This function searches for the best decision threshold for each emotion label by testing values from 0.20 to 0.75 and selecting the one that produces the highest F1 score on validation data. Instead of using a fixed 0.5 cutoff, it computes label-specific thresholds to better match each class's distribution. This improves multi-label performance because different emotions have different score ranges, and optimized thresholds significantly boost overall F1 and recall.**"
      ],
      "metadata": {
        "id": "3-1mMGHN-6W2"
      },
      "id": "3-1mMGHN-6W2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e4a5ba",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.364778Z",
          "iopub.status.busy": "2025-11-28T12:48:22.364238Z",
          "iopub.status.idle": "2025-11-28T12:48:22.368817Z",
          "shell.execute_reply": "2025-11-28T12:48:22.368281Z"
        },
        "id": "89e4a5ba",
        "papermill": {
          "duration": 0.016086,
          "end_time": "2025-11-28T12:48:22.369797",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.353711",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def find_optimal_thresholds(val_probs, val_labels):\n",
        "    thresholds = {}\n",
        "    print(\"Finding Optimal Thresholds per Label\")\n",
        "\n",
        "    for i, label in enumerate(LABEL_COLS):\n",
        "        best_f1 = 0\n",
        "        best_thresh = 0.5\n",
        "\n",
        "        for thresh in np.arange(0.2, 0.8, 0.05):\n",
        "            preds = (val_probs[:, i] >= thresh).astype(int)\n",
        "            f1 = f1_score(val_labels[:, i], preds, zero_division=0)\n",
        "\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresh = thresh\n",
        "\n",
        "        thresholds[label] = best_thresh\n",
        "        print(f\"{label:10s}: threshold={best_thresh:.2f}, F1={best_f1:.4f}\")\n",
        "\n",
        "\n",
        "    return thresholds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA PREPARATION FOR TRAINING"
      ],
      "metadata": {
        "id": "jDEIyXzg_OsV"
      },
      "id": "jDEIyXzg_OsV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b67cb3da",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.390562Z",
          "iopub.status.busy": "2025-11-28T12:48:22.390369Z",
          "iopub.status.idle": "2025-11-28T12:48:22.406579Z",
          "shell.execute_reply": "2025-11-28T12:48:22.406076Z"
        },
        "id": "b67cb3da",
        "papermill": {
          "duration": 0.027769,
          "end_time": "2025-11-28T12:48:22.407603",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.379834",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "texts = df[\"text\"].astype(str).tolist()\n",
        "labels = df[LABEL_COLS].values\n",
        "\n",
        "df = pd.DataFrame({\"text\": texts})\n",
        "for i, col in enumerate(LABEL_COLS):\n",
        "    df[col] = labels[:, i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aafdd807",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.428611Z",
          "iopub.status.busy": "2025-11-28T12:48:22.428435Z",
          "iopub.status.idle": "2025-11-28T12:48:22.437495Z",
          "shell.execute_reply": "2025-11-28T12:48:22.436868Z"
        },
        "id": "aafdd807",
        "outputId": "a9e5f599-acc4-4f9c-d604-463d0afdecfb",
        "papermill": {
          "duration": 0.020623,
          "end_time": "2025-11-28T12:48:22.438545",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.417922",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 12501 | Val: 1563 | Test: 1563\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converts the data into HuggingFace Dataset format, applies tokenization, and attaches the emotion label vectors to each sample. Enables dynamic padding for efficient batching and smoother model training.**"
      ],
      "metadata": {
        "id": "rLbGRxIA_TY0"
      },
      "id": "rLbGRxIA_TY0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4142fc43",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.460247Z",
          "iopub.status.busy": "2025-11-28T12:48:22.459668Z",
          "iopub.status.idle": "2025-11-28T12:48:22.494224Z",
          "shell.execute_reply": "2025-11-28T12:48:22.493621Z"
        },
        "id": "4142fc43",
        "papermill": {
          "duration": 0.046256,
          "end_time": "2025-11-28T12:48:22.495420",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.449164",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "dataset = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df),\n",
        "    \"validation\": Dataset.from_pandas(val_df),\n",
        "    \"test\": Dataset.from_pandas(test_df),\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b363aef3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:22.516704Z",
          "iopub.status.busy": "2025-11-28T12:48:22.516495Z",
          "iopub.status.idle": "2025-11-28T12:48:27.566423Z",
          "shell.execute_reply": "2025-11-28T12:48:27.565790Z"
        },
        "id": "b363aef3",
        "outputId": "ba0da5eb-b82a-4a7e-9e09-249d4309fe5e",
        "papermill": {
          "duration": 5.06165,
          "end_time": "2025-11-28T12:48:27.567496",
          "exception": false,
          "start_time": "2025-11-28T12:48:22.505846",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "867f875cfea04fea9bdd7fe5b5c3aefa",
            "dd771acb6d3e44aea50f2456a988f554",
            "ed1cfe2ea97c4d0a9b5e6c1cf54fd524",
            "ea4c832d6b184e74a89a7d2cc4285d17",
            "0618ecc90d224960b7b984bd078e194a",
            "3a3ee323fb0c4388942a3cb74dd14930"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "867f875cfea04fea9bdd7fe5b5c3aefa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd771acb6d3e44aea50f2456a988f554",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed1cfe2ea97c4d0a9b5e6c1cf54fd524",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea4c832d6b184e74a89a7d2cc4285d17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12501 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0618ecc90d224960b7b984bd078e194a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1563 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a3ee323fb0c4388942a3cb74dd14930",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1563 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(DEBERTA_MODEL)\n",
        "\n",
        "tokenized_datasets = dataset.map(\n",
        "    lambda examples: tokenizer(examples[\"text\"], truncation=True),\n",
        "    batched=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed53f027",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:27.590662Z",
          "iopub.status.busy": "2025-11-28T12:48:27.590246Z",
          "iopub.status.idle": "2025-11-28T12:48:29.118845Z",
          "shell.execute_reply": "2025-11-28T12:48:29.118267Z"
        },
        "id": "ed53f027",
        "outputId": "582e782f-0d5c-4728-b227-c184525ccc0c",
        "papermill": {
          "duration": 1.541214,
          "end_time": "2025-11-28T12:48:29.119972",
          "exception": false,
          "start_time": "2025-11-28T12:48:27.578758",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "2333a4623ca84415883931cc736cd4b9",
            "9c224865fe3542d281ec14fa4d289276",
            "3694eca696834e1facfb84c4b7cdff32"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2333a4623ca84415883931cc736cd4b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/12501 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c224865fe3542d281ec14fa4d289276",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1563 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3694eca696834e1facfb84c4b7cdff32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1563 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def set_labels(example):\n",
        "    example[\"labels\"] = [float(example[col]) for col in LABEL_COLS]\n",
        "    return example\n",
        "\n",
        "tokenized_datasets = tokenized_datasets.map(set_labels)\n",
        "\n",
        "# dynamic padding per batch\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING\n",
        "1. Trains the DeBERTa model multiple times using different random seeds to improve robustness and reduce variance.\n",
        "\n",
        "2. Logs each run to Weights & Biases with its own config for tracking experiments.\n",
        "\n",
        "3. Initializes a fresh model and training setup for every seed to ensure independent runs.\n",
        "\n",
        "4. Trains with Focal Loss, cosine LR scheduling, gradient accumulation, and logs metrics.\n",
        "\n",
        "5. Evaluates each model on the test set and stores the seed-wise results.\n",
        "\n",
        "6. Generates validation predictions\n",
        "for threshold tuning and test predictions for ensembling.\n",
        "\n",
        "7. Saves each trained model and\n",
        "tokenizer, uploads them to W&B as artifacts for reproducibility."
      ],
      "metadata": {
        "id": "SYnPBy43_jTK"
      },
      "id": "SYnPBy43_jTK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c883c8d9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T12:48:29.171488Z",
          "iopub.status.busy": "2025-11-28T12:48:29.171283Z",
          "iopub.status.idle": "2025-11-28T14:54:49.860412Z",
          "shell.execute_reply": "2025-11-28T14:54:49.859465Z"
        },
        "id": "c883c8d9",
        "outputId": "402b665f-5c26-4330-e627-c33cc0e783e9",
        "papermill": {
          "duration": 7580.716045,
          "end_time": "2025-11-28T14:54:49.875411",
          "exception": false,
          "start_time": "2025-11-28T12:48:29.159366",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "053d35cd959743f8984c9c9f86f5c794",
            "8692924dc4a24644a2cadb3c04431e30"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAINING MODEL WITH SEED 42 (1/3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251128_124829-f92ty5ks\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeberta-large-seed42\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/f92ty5ks\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "053d35cd959743f8984c9c9f86f5c794",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipykernel_20/1058363764.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = CustomTrainer(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8692924dc4a24644a2cadb3c04431e30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/874M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2737' max='2737' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2737/2737 39:45, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>F1 Anger</th>\n",
              "      <th>F1 Joy</th>\n",
              "      <th>F1 Fear</th>\n",
              "      <th>F1 Surprise</th>\n",
              "      <th>F1 Sadness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>0.028772</td>\n",
              "      <td>0.694149</td>\n",
              "      <td>0.660287</td>\n",
              "      <td>0.703963</td>\n",
              "      <td>0.790594</td>\n",
              "      <td>0.702962</td>\n",
              "      <td>0.612940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.024200</td>\n",
              "      <td>0.024246</td>\n",
              "      <td>0.765423</td>\n",
              "      <td>0.732461</td>\n",
              "      <td>0.793548</td>\n",
              "      <td>0.796875</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.747475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.014700</td>\n",
              "      <td>0.024315</td>\n",
              "      <td>0.806500</td>\n",
              "      <td>0.794979</td>\n",
              "      <td>0.810750</td>\n",
              "      <td>0.831962</td>\n",
              "      <td>0.800983</td>\n",
              "      <td>0.793824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.007900</td>\n",
              "      <td>0.029326</td>\n",
              "      <td>0.812638</td>\n",
              "      <td>0.766265</td>\n",
              "      <td>0.823280</td>\n",
              "      <td>0.868393</td>\n",
              "      <td>0.798561</td>\n",
              "      <td>0.806691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.035346</td>\n",
              "      <td>0.821807</td>\n",
              "      <td>0.813824</td>\n",
              "      <td>0.829676</td>\n",
              "      <td>0.857803</td>\n",
              "      <td>0.791629</td>\n",
              "      <td>0.816102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>0.038970</td>\n",
              "      <td>0.829688</td>\n",
              "      <td>0.830270</td>\n",
              "      <td>0.832421</td>\n",
              "      <td>0.866555</td>\n",
              "      <td>0.801770</td>\n",
              "      <td>0.817424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.040043</td>\n",
              "      <td>0.827303</td>\n",
              "      <td>0.817778</td>\n",
              "      <td>0.831878</td>\n",
              "      <td>0.869757</td>\n",
              "      <td>0.798923</td>\n",
              "      <td>0.818182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Seed 42 Test Metrics: {'eval_loss': 0.04215562716126442, 'eval_macro_f1': 0.8177690602913955, 'eval_f1_anger': 0.8105625717566016, 'eval_f1_joy': 0.8056968463886063, 'eval_f1_fear': 0.8573059360730593, 'eval_f1_surprise': 0.8078725398313028, 'eval_f1_sadness': 0.8074074074074074, 'eval_runtime': 12.3373, 'eval_samples_per_second': 126.689, 'eval_steps_per_second': 15.887, 'epoch': 7.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./deberta_large_seed_42)... Done. 5.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_42; uploading output.log; uploading config.yaml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_42\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/f1_anger ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñá‚ñà‚ñá‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/f1_fear ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/f1_joy ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/f1_sadness ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/f1_surprise ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/macro_f1 ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ‚ñà‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                f1_anger ‚ñÅ‚ñÑ‚ñá‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 f1_fear ‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  f1_joy ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              f1_sadness ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             f1_surprise ‚ñÅ‚ñÖ‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                macro_f1 ‚ñÅ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           test/f1_anger ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/f1_fear ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/f1_joy ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         test/f1_sadness ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test/f1_surprise ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               test/loss ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           test/macro_f1 ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/runtime ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test/samples_per_second ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test/steps_per_second ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/grad_norm ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÜ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/f1_anger 0.81056\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/f1_fear 0.85731\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              eval/f1_joy 0.8057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/f1_sadness 0.80741\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/f1_surprise 0.80787\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/loss 0.04216\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/macro_f1 0.81777\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/runtime 12.3373\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/samples_per_second 126.689\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/steps_per_second 15.887\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 f1_anger 0.81056\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  f1_fear 0.85731\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   f1_joy 0.8057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               f1_sadness 0.80741\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              f1_surprise 0.80787\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 macro_f1 0.81777\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/f1_anger 0.81056\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/f1_fear 0.85731\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test/f1_joy 0.8057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test/f1_sadness 0.80741\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         test/f1_surprise 0.80787\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                test/loss 0.04216\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/macro_f1 0.81777\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/runtime 12.3457\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/samples_per_second 126.603\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test/steps_per_second 15.876\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 6470304860092128.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 2737\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 0.27305\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 0.0017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 0.01317\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 2389.1921\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 36.626\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 1.146\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mdeberta-large-seed42\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/f92ty5ks\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251128_124829-f92ty5ks/logs\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAINING MODEL WITH SEED 2025 (2/3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251128_133029-karya2d6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeberta-large-seed2025\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/karya2d6\u001b[0m\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipykernel_20/1058363764.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = CustomTrainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2737' max='2737' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2737/2737 39:47, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>F1 Anger</th>\n",
              "      <th>F1 Joy</th>\n",
              "      <th>F1 Fear</th>\n",
              "      <th>F1 Surprise</th>\n",
              "      <th>F1 Sadness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.033600</td>\n",
              "      <td>0.032413</td>\n",
              "      <td>0.555810</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.703043</td>\n",
              "      <td>0.722803</td>\n",
              "      <td>0.421995</td>\n",
              "      <td>0.531212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.025114</td>\n",
              "      <td>0.763032</td>\n",
              "      <td>0.756021</td>\n",
              "      <td>0.739694</td>\n",
              "      <td>0.815524</td>\n",
              "      <td>0.748487</td>\n",
              "      <td>0.755435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.016500</td>\n",
              "      <td>0.026092</td>\n",
              "      <td>0.789969</td>\n",
              "      <td>0.773740</td>\n",
              "      <td>0.770810</td>\n",
              "      <td>0.844874</td>\n",
              "      <td>0.784383</td>\n",
              "      <td>0.776037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.008300</td>\n",
              "      <td>0.027901</td>\n",
              "      <td>0.801669</td>\n",
              "      <td>0.788636</td>\n",
              "      <td>0.799552</td>\n",
              "      <td>0.848961</td>\n",
              "      <td>0.773333</td>\n",
              "      <td>0.797863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.004900</td>\n",
              "      <td>0.032822</td>\n",
              "      <td>0.816143</td>\n",
              "      <td>0.804009</td>\n",
              "      <td>0.804746</td>\n",
              "      <td>0.852860</td>\n",
              "      <td>0.820976</td>\n",
              "      <td>0.798122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.037599</td>\n",
              "      <td>0.822369</td>\n",
              "      <td>0.810268</td>\n",
              "      <td>0.814735</td>\n",
              "      <td>0.860884</td>\n",
              "      <td>0.824156</td>\n",
              "      <td>0.801802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.038836</td>\n",
              "      <td>0.823324</td>\n",
              "      <td>0.812990</td>\n",
              "      <td>0.811404</td>\n",
              "      <td>0.862939</td>\n",
              "      <td>0.824978</td>\n",
              "      <td>0.804309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Seed 2025 Test Metrics: {'eval_loss': 0.040435243397951126, 'eval_macro_f1': 0.8104835726894171, 'eval_f1_anger': 0.8032036613272311, 'eval_f1_joy': 0.7805383022774328, 'eval_f1_fear': 0.8638985005767013, 'eval_f1_surprise': 0.8044077134986226, 'eval_f1_sadness': 0.8003696857670979, 'eval_runtime': 12.405, 'eval_samples_per_second': 125.997, 'eval_steps_per_second': 15.8, 'epoch': 7.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./deberta_large_seed_2025)... Done. 5.0s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_2025; uploading wandb-summary.json; uploading config.yaml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_2025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_2025; uploading data\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_2025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/f1_anger ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/f1_fear ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/f1_joy ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÜ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/f1_sadness ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/f1_surprise ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/macro_f1 ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                f1_anger ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 f1_fear ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  f1_joy ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñà‚ñÜ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              f1_sadness ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             f1_surprise ‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                macro_f1 ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           test/f1_anger ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/f1_fear ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/f1_joy ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         test/f1_sadness ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test/f1_surprise ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               test/loss ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           test/macro_f1 ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/runtime ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test/samples_per_second ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test/steps_per_second ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/grad_norm ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/f1_anger 0.8032\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/f1_fear 0.8639\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              eval/f1_joy 0.78054\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/f1_sadness 0.80037\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/f1_surprise 0.80441\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/loss 0.04044\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/macro_f1 0.81048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/runtime 12.405\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/samples_per_second 125.997\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/steps_per_second 15.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 f1_anger 0.8032\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  f1_fear 0.8639\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   f1_joy 0.78054\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               f1_sadness 0.80037\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              f1_surprise 0.80441\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 macro_f1 0.81048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/f1_anger 0.8032\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/f1_fear 0.8639\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test/f1_joy 0.78054\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test/f1_sadness 0.80037\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         test/f1_surprise 0.80441\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                test/loss 0.04044\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/macro_f1 0.81048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/runtime 12.4359\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/samples_per_second 125.684\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test/steps_per_second 15.761\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 6470852743055910.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 2737\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 0.0499\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 0.0017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 0.01423\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 2388.7785\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 36.633\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 1.146\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mdeberta-large-seed2025\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/karya2d6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251128_133029-karya2d6/logs\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAINING MODEL WITH SEED 123 (3/3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251128_141241-pybz1mxa\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeberta-large-seed123\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/pybz1mxa\u001b[0m\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipykernel_20/1058363764.py:58: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = CustomTrainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2737' max='2737' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2737/2737 39:58, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>F1 Anger</th>\n",
              "      <th>F1 Joy</th>\n",
              "      <th>F1 Fear</th>\n",
              "      <th>F1 Surprise</th>\n",
              "      <th>F1 Sadness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>0.029427</td>\n",
              "      <td>0.663984</td>\n",
              "      <td>0.688780</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.806630</td>\n",
              "      <td>0.667268</td>\n",
              "      <td>0.585812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.023600</td>\n",
              "      <td>0.024782</td>\n",
              "      <td>0.753695</td>\n",
              "      <td>0.750831</td>\n",
              "      <td>0.757259</td>\n",
              "      <td>0.822441</td>\n",
              "      <td>0.684157</td>\n",
              "      <td>0.753788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.014800</td>\n",
              "      <td>0.023573</td>\n",
              "      <td>0.803126</td>\n",
              "      <td>0.769412</td>\n",
              "      <td>0.810515</td>\n",
              "      <td>0.853246</td>\n",
              "      <td>0.787611</td>\n",
              "      <td>0.794848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>0.027873</td>\n",
              "      <td>0.824732</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.824635</td>\n",
              "      <td>0.849887</td>\n",
              "      <td>0.808788</td>\n",
              "      <td>0.821072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.035171</td>\n",
              "      <td>0.827471</td>\n",
              "      <td>0.815402</td>\n",
              "      <td>0.834202</td>\n",
              "      <td>0.861469</td>\n",
              "      <td>0.806097</td>\n",
              "      <td>0.820183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.039089</td>\n",
              "      <td>0.832348</td>\n",
              "      <td>0.820112</td>\n",
              "      <td>0.842220</td>\n",
              "      <td>0.859649</td>\n",
              "      <td>0.812994</td>\n",
              "      <td>0.826764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.040234</td>\n",
              "      <td>0.832129</td>\n",
              "      <td>0.823661</td>\n",
              "      <td>0.841880</td>\n",
              "      <td>0.859688</td>\n",
              "      <td>0.808772</td>\n",
              "      <td>0.826642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Seed 123 Test Metrics: {'eval_loss': 0.04149944335222244, 'eval_macro_f1': 0.8184330712041857, 'eval_f1_anger': 0.8090909090909092, 'eval_f1_joy': 0.8132094943240454, 'eval_f1_fear': 0.8659315147997679, 'eval_f1_surprise': 0.7930720145852324, 'eval_f1_sadness': 0.8108614232209738, 'eval_runtime': 12.476, 'eval_samples_per_second': 125.28, 'eval_steps_per_second': 15.71, 'epoch': 7.0}\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./deberta_large_seed_123)... Done. 5.5s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_123; uploading output.log; uploading config.yaml\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_123\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_123; uploading summary, console lines 6-6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: uploading artifact deberta_large_seed_123\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/f1_anger ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/f1_fear ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/f1_joy ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/f1_sadness ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/f1_surprise ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/macro_f1 ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñá‚ñà‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                f1_anger ‚ñÅ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 f1_fear ‚ñÅ‚ñÉ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  f1_joy ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              f1_sadness ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             f1_surprise ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                macro_f1 ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           test/f1_anger ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/f1_fear ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/f1_joy ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         test/f1_sadness ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test/f1_surprise ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               test/loss ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           test/macro_f1 ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/runtime ‚ñà‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test/samples_per_second ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   test/steps_per_second ‚ñÅ‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/grad_norm ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/f1_anger 0.80909\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/f1_fear 0.86593\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              eval/f1_joy 0.81321\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/f1_sadness 0.81086\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         eval/f1_surprise 0.79307\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/loss 0.0415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/macro_f1 0.81843\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/runtime 12.476\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/samples_per_second 125.28\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/steps_per_second 15.71\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 f1_anger 0.80909\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  f1_fear 0.86593\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   f1_joy 0.81321\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               f1_sadness 0.81086\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              f1_surprise 0.79307\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 macro_f1 0.81843\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/f1_anger 0.80909\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/f1_fear 0.86593\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test/f1_joy 0.81321\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          test/f1_sadness 0.81086\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         test/f1_surprise 0.79307\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                test/loss 0.0415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            test/macro_f1 0.81843\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             test/runtime 12.4765\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test/samples_per_second 125.276\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test/steps_per_second 15.71\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 6482305499229054.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 2737\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 0.19775\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 0.0015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 0.01294\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 2399.469\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 36.469\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 1.141\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mdeberta-large-seed123\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/pybz1mxa\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251128_141241-pybz1mxa/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "all_val_predictions = []\n",
        "all_test_predictions = []\n",
        "seed_results = []\n",
        "\n",
        "for seed_idx, seed in enumerate(SEEDS):\n",
        "    print(f\"TRAINING MODEL WITH SEED {seed} ({seed_idx+1}/{len(SEEDS)})\")\n",
        "\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Initialize wandb\n",
        "    wandb.init(\n",
        "        project=\"23f3001910-t32025\",\n",
        "        name=f\"deberta-large-seed{seed}\",\n",
        "        config={\n",
        "            \"seed\": seed,\n",
        "            \"batch_size\": BATCH_SIZE,\n",
        "            \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
        "            \"effective_batch_size\": BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS,\n",
        "            \"epochs\": EPOCHS,\n",
        "            \"learning_rate\": LEARNING_RATE,\n",
        "            \"focal_loss\": True,\n",
        "            \"lr_scheduler\": \"cosine\",\n",
        "            \"warmup_ratio\": 0.1,\n",
        "        },\n",
        "    )\n",
        "\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        DEBERTA_MODEL,\n",
        "        problem_type=\"multi_label_classification\",\n",
        "        num_labels=NUM_LABELS,\n",
        "    )\n",
        "\n",
        "#training related arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_seed_{seed}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        save_total_limit=1,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        weight_decay=0.01,\n",
        "        load_best_model_at_end=False,\n",
        "        metric_for_best_model=\"macro_f1\",\n",
        "        greater_is_better=True,\n",
        "        logging_dir=f\"./logs_seed_{seed}\",\n",
        "        logging_steps=50,\n",
        "        report_to=[\"wandb\"],\n",
        "        warmup_ratio=0.1,\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "        seed=seed,\n",
        "    )\n",
        "\n",
        "#using custom trainer\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "    print(f\"\\nSeed {seed} Test Metrics: {metrics}\")\n",
        "    seed_results.append(metrics)\n",
        "\n",
        "    # Get validation predictions for threshold tuning\n",
        "    val_outputs = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "    val_probs = torch.sigmoid(torch.tensor(val_outputs.predictions)).numpy()\n",
        "    all_val_predictions.append(val_probs)\n",
        "\n",
        "    # Get test predictions\n",
        "    test_outputs = trainer.predict(tokenized_datasets[\"test\"])\n",
        "    test_probs = torch.sigmoid(torch.tensor(test_outputs.predictions)).numpy()\n",
        "    all_test_predictions.append(test_probs)\n",
        "\n",
        "    # Save model\n",
        "    model_dir = f\"./deberta_large_seed_{seed}\"\n",
        "    trainer.save_model(model_dir)\n",
        "    tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "    artifact = wandb.Artifact(f\"deberta_large_seed_{seed}\", type=\"model\")\n",
        "    artifact.add_dir(model_dir)\n",
        "    wandb.log_artifact(artifact)\n",
        "\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad702e5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T14:54:49.906800Z",
          "iopub.status.busy": "2025-11-28T14:54:49.906321Z",
          "iopub.status.idle": "2025-11-28T14:54:50.231352Z",
          "shell.execute_reply": "2025-11-28T14:54:50.230540Z"
        },
        "id": "3ad702e5",
        "papermill": {
          "duration": 0.341996,
          "end_time": "2025-11-28T14:54:50.232576",
          "exception": false,
          "start_time": "2025-11-28T14:54:49.890580",
          "status": "completed"
        },
        "tags": [],
        "outputId": "960ca650-c99c-494c-80d4-15f760cb02d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finding Optimal Thresholds per Label\n",
            "==================================================\n",
            "anger     : threshold=0.30, F1=0.8468\n",
            "joy       : threshold=0.50, F1=0.8457\n",
            "fear      : threshold=0.40, F1=0.8783\n",
            "surprise  : threshold=0.35, F1=0.8324\n",
            "sadness   : threshold=0.45, F1=0.8326\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ensemble_val_probs = np.mean(all_val_predictions, axis=0)\n",
        "val_labels = tokenized_datasets[\"validation\"][LABEL_COLS[0]]\n",
        "val_labels_array = np.array([tokenized_datasets[\"validation\"][col] for col in LABEL_COLS]).T\n",
        "\n",
        "# Find optimal thresholds using ensemble validation predictions\n",
        "optimal_thresholds = find_optimal_thresholds(ensemble_val_probs, val_labels_array)\n",
        "\n",
        "# Average test predictions from all seeds\n",
        "ensemble_test_probs = np.mean(all_test_predictions, axis=0)\n",
        "\n",
        "# Apply optimal thresholds\n",
        "ensemble_preds = np.zeros_like(ensemble_test_probs)\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "    ensemble_preds[:, i] = (ensemble_test_probs[:, i] >= optimal_thresholds[label]).astype(int)\n",
        "\n",
        "# Calculate ensemble metrics\n",
        "test_labels = tokenized_datasets[\"test\"][LABEL_COLS[0]]\n",
        "test_labels_array = np.array([tokenized_datasets[\"test\"][col] for col in LABEL_COLS]).T\n",
        "\n",
        "ensemble_macro_f1 = f1_score(test_labels_array, ensemble_preds, average=\"macro\", zero_division=0)\n",
        "ensemble_per_label_f1 = f1_score(test_labels_array, ensemble_preds, average=None, zero_division=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4415d2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T14:54:50.265213Z",
          "iopub.status.busy": "2025-11-28T14:54:50.264660Z",
          "iopub.status.idle": "2025-11-28T14:54:50.269471Z",
          "shell.execute_reply": "2025-11-28T14:54:50.268867Z"
        },
        "id": "8f4415d2",
        "papermill": {
          "duration": 0.022387,
          "end_time": "2025-11-28T14:54:50.270553",
          "exception": false,
          "start_time": "2025-11-28T14:54:50.248166",
          "status": "completed"
        },
        "tags": [],
        "outputId": "3471dd01-1ec3-4dce-a70c-165184449e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1: 0.8329\n",
            "anger     : 0.8294\n",
            "joy       : 0.8136\n",
            "fear      : 0.8736\n",
            "surprise  : 0.8228\n",
            "sadness   : 0.8253\n",
            "Seed 42: Macro F1 = 0.8178\n",
            "Seed 2025: Macro F1 = 0.8105\n",
            "Seed 123: Macro F1 = 0.8184\n"
          ]
        }
      ],
      "source": [
        "print(f\"Macro F1: {ensemble_macro_f1:.4f}\")\n",
        "for label, f1 in zip(LABEL_COLS, ensemble_per_label_f1):\n",
        "    print(f\"{label:10s}: {f1:.4f}\")\n",
        "\n",
        "for seed, result in zip(SEEDS, seed_results):\n",
        "    print(f\"Seed {seed}: Macro F1 = {result['eval_macro_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJVrf6ckAN1I"
      },
      "id": "lJVrf6ckAN1I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESULTS"
      ],
      "metadata": {
        "id": "shweUjJ6AOEs"
      },
      "id": "shweUjJ6AOEs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEED 42**\n",
        "- Macro F1: 0.817\n",
        "\n",
        "- Anger F1: 0.81\n",
        "\n",
        "- Joy F1: 0.80\n",
        "\n",
        "- Fear F1: 0.85\n",
        "\n",
        "- Surprise F1: 0.80\n",
        "\n",
        "- Sadness F1: 0.80\n",
        "\n",
        "- Test Loss: 0.04216\n",
        "\n",
        "Train, Test and Validation Data performed similarly with a score around ~ 0.817\n",
        "\n",
        "**SEED 2025**\n",
        "- Macro F1: 0.81\n",
        "\n",
        "- Anger F1: 0.80\n",
        "\n",
        "- Joy F1: 0.78\n",
        "\n",
        "- Fear F1: 0.86\n",
        "\n",
        "- Surprise F1: 0.80\n",
        "\n",
        "- Sadness F1: 0.80\n",
        "\n",
        "- Test Loss: 0.0446\n",
        "\n",
        "Train, Test and Validation Data performed similarly with a score around ~ 0.81\n",
        "\n",
        "**SEED 42**\n",
        "- Macro F1: 0.818\n",
        "\n",
        "- Anger F1: 0.80\n",
        "\n",
        "- Joy F1: 0.81\n",
        "\n",
        "- Fear F1: 0.86\n",
        "\n",
        "- Surprise F1: 0.79\n",
        "\n",
        "- Sadness F1: 0.81\n",
        "\n",
        "- Test Loss: 0.0415\n",
        "\n",
        "Train, Test and Validation Data performed similarly with a score around ~ 0.818"
      ],
      "metadata": {
        "id": "uhQNCie6AR1G"
      },
      "id": "uhQNCie6AR1G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimal Thresholds**\n",
        "- Macro F1: 0.8329\n",
        "- anger     : 0.82\n",
        "- joy       : 0.81\n",
        "- fear      : 0.87\n",
        "- surprise  : 0.82\n",
        "- sadness   : 0.82\n",
        "- Seed 42: Macro F1 = 0.817\n",
        "- Seed 2025: Macro F1 = 0.81\n",
        "- Seed 123: Macro F1 = 0.818"
      ],
      "metadata": {
        "id": "oD52czlGBrYT"
      },
      "id": "oD52czlGBrYT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INFERENCE"
      ],
      "metadata": {
        "id": "9U-DQqBsB9zN"
      },
      "id": "9U-DQqBsB9zN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ef375e",
      "metadata": {
        "id": "a9ef375e",
        "papermill": {
          "duration": 0.015217,
          "end_time": "2025-11-28T14:54:50.301245",
          "exception": false,
          "start_time": "2025-11-28T14:54:50.286028",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bed094b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T14:54:50.333204Z",
          "iopub.status.busy": "2025-11-28T14:54:50.332642Z",
          "iopub.status.idle": "2025-11-28T14:54:50.378782Z",
          "shell.execute_reply": "2025-11-28T14:54:50.378168Z"
        },
        "id": "4bed094b",
        "papermill": {
          "duration": 0.064021,
          "end_time": "2025-11-28T14:54:50.380118",
          "exception": false,
          "start_time": "2025-11-28T14:54:50.316097",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "TEST_PATH = \"/kaggle/input/dlgenai/test_clean.csv\"\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "texts = test[\"text\"].astype(str).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c61149",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T14:54:50.412522Z",
          "iopub.status.busy": "2025-11-28T14:54:50.411793Z",
          "iopub.status.idle": "2025-11-28T14:55:32.304433Z",
          "shell.execute_reply": "2025-11-28T14:55:32.303513Z"
        },
        "id": "47c61149",
        "papermill": {
          "duration": 41.924612,
          "end_time": "2025-11-28T14:55:32.320289",
          "exception": false,
          "start_time": "2025-11-28T14:54:50.395677",
          "status": "completed"
        },
        "tags": [],
        "outputId": "db88f837-b853-4e0e-8b42-c51c816e0c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model with seed 42...\n",
            "Predictions generated\n",
            "Loading model with seed 2025...\n",
            "Predictions generated\n",
            "Loading model with seed 123...\n",
            "Predictions generated\n"
          ]
        }
      ],
      "source": [
        "all_model_preds = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    print(f\"Loading model with seed {seed}...\")\n",
        "    model_dir = f\"./deberta_large_seed_{seed}\"\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    batch_preds = []\n",
        "    INFERENCE_BATCH_SIZE = 16\n",
        "\n",
        "    for i in range(0, len(texts), INFERENCE_BATCH_SIZE):\n",
        "        batch_texts = texts[i:i+INFERENCE_BATCH_SIZE]\n",
        "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "            batch_preds.extend(probs)\n",
        "\n",
        "    all_model_preds.append(np.array(batch_preds))\n",
        "    print(f\"Predictions generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d50344c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T14:55:32.351564Z",
          "iopub.status.busy": "2025-11-28T14:55:32.350882Z",
          "iopub.status.idle": "2025-11-28T14:55:32.360348Z",
          "shell.execute_reply": "2025-11-28T14:55:32.359805Z"
        },
        "id": "0d50344c",
        "papermill": {
          "duration": 0.026355,
          "end_time": "2025-11-28T14:55:32.361410",
          "exception": false,
          "start_time": "2025-11-28T14:55:32.335055",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "final_probs = np.mean(all_model_preds, axis=0)\n",
        "\n",
        "# Apply optimal thresholds\n",
        "final_preds = np.zeros_like(final_probs)\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "    final_preds[:, i] = (final_probs[:, i] >= optimal_thresholds[label]).astype(int)\n",
        "\n",
        "# Create submission\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "    test[label] = final_preds[:, i].astype(int)\n",
        "\n",
        "columns_to_keep = ['id', 'anger', 'fear', 'joy', 'sadness', 'surprise']\n",
        "test = test[columns_to_keep]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e40839",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T14:55:32.393288Z",
          "iopub.status.busy": "2025-11-28T14:55:32.392750Z",
          "iopub.status.idle": "2025-11-28T14:55:32.404555Z",
          "shell.execute_reply": "2025-11-28T14:55:32.403907Z"
        },
        "id": "d7e40839",
        "papermill": {
          "duration": 0.029059,
          "end_time": "2025-11-28T14:55:32.405757",
          "exception": false,
          "start_time": "2025-11-28T14:55:32.376698",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "test.to_csv(\"submission_seed_ensemble.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100fce3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-28T14:55:32.436303Z",
          "iopub.status.busy": "2025-11-28T14:55:32.436041Z",
          "iopub.status.idle": "2025-11-28T14:55:32.440167Z",
          "shell.execute_reply": "2025-11-28T14:55:32.439443Z"
        },
        "id": "100fce3f",
        "papermill": {
          "duration": 0.020624,
          "end_time": "2025-11-28T14:55:32.441216",
          "exception": false,
          "start_time": "2025-11-28T14:55:32.420592",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('optimal_thresholds.json', 'w') as f:\n",
        "    json.dump(optimal_thresholds, f, indent=2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 8735525,
          "sourceId": 13730092,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31193,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7682.822315,
      "end_time": "2025-11-28T14:55:35.553071",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-11-28T12:47:32.730756",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}