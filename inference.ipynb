{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a6b6ec",
   "metadata": {
    "id": "3Hst-joOri8b",
    "papermill": {
     "duration": 0.004452,
     "end_time": "2025-11-30T17:37:21.430321",
     "exception": false,
     "start_time": "2025-11-30T17:37:21.425869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1f509f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:37:21.438759Z",
     "iopub.status.busy": "2025-11-30T17:37:21.438501Z",
     "iopub.status.idle": "2025-11-30T17:38:56.311382Z",
     "shell.execute_reply": "2025-11-30T17:38:56.310423Z"
    },
    "id": "BQ1RvtNEmgz2",
    "papermill": {
     "duration": 94.878899,
     "end_time": "2025-11-30T17:38:56.313016",
     "exception": false,
     "start_time": "2025-11-30T17:37:21.434117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\r\n",
      "Collecting accelerate\r\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting bitsandbytes\r\n",
      "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\r\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\r\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\r\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\r\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.5.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, bitsandbytes, accelerate\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.33.1\r\n",
      "    Uninstalling huggingface-hub-0.33.1:\r\n",
      "      Successfully uninstalled huggingface-hub-0.33.1\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.21.2\r\n",
      "    Uninstalling tokenizers-0.21.2:\r\n",
      "      Successfully uninstalled tokenizers-0.21.2\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.52.4\r\n",
      "    Uninstalling transformers-4.52.4:\r\n",
      "      Successfully uninstalled transformers-4.52.4\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 1.8.1\r\n",
      "    Uninstalling accelerate-1.8.1:\r\n",
      "      Successfully uninstalled accelerate-1.8.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed accelerate-1.12.0 bitsandbytes-0.48.2 huggingface-hub-0.36.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tokenizers-0.22.1 transformers-4.57.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85266c5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:38:56.370019Z",
     "iopub.status.busy": "2025-11-30T17:38:56.369778Z",
     "iopub.status.idle": "2025-11-30T17:39:10.255563Z",
     "shell.execute_reply": "2025-11-30T17:39:10.254762Z"
    },
    "id": "54KICMicra81",
    "papermill": {
     "duration": 13.915669,
     "end_time": "2025-11-30T17:39:10.256992",
     "exception": false,
     "start_time": "2025-11-30T17:38:56.341323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import wandb\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ed37d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:10.314177Z",
     "iopub.status.busy": "2025-11-30T17:39:10.313958Z",
     "iopub.status.idle": "2025-11-30T17:39:10.543729Z",
     "shell.execute_reply": "2025-11-30T17:39:10.542819Z"
    },
    "id": "VP7wPNlarda1",
    "outputId": "6449b69e-6bc0-4f3d-c632-79c7f68308de",
    "papermill": {
     "duration": 0.259576,
     "end_time": "2025-11-30T17:39:10.544987",
     "exception": false,
     "start_time": "2025-11-30T17:39:10.285411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"16a767377715590d2d5fe6351174577f96db6dc6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059e1ed",
   "metadata": {
    "id": "tiaHwiX-rn28",
    "papermill": {
     "duration": 0.074056,
     "end_time": "2025-11-30T17:39:10.648229",
     "exception": false,
     "start_time": "2025-11-30T17:39:10.574173",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1485d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:10.704607Z",
     "iopub.status.busy": "2025-11-30T17:39:10.703994Z",
     "iopub.status.idle": "2025-11-30T17:39:10.757178Z",
     "shell.execute_reply": "2025-11-30T17:39:10.756571Z"
    },
    "id": "wYM8bnxWr0d3",
    "papermill": {
     "duration": 0.082542,
     "end_time": "2025-11-30T17:39:10.758395",
     "exception": false,
     "start_time": "2025-11-30T17:39:10.675853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABEL_COLS = [\"anger\", \"joy\", \"fear\", \"surprise\", \"sadness\"]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c60ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:10.816997Z",
     "iopub.status.busy": "2025-11-30T17:39:10.816698Z",
     "iopub.status.idle": "2025-11-30T17:39:10.820581Z",
     "shell.execute_reply": "2025-11-30T17:39:10.819991Z"
    },
    "id": "-MHNDQowr6wK",
    "papermill": {
     "duration": 0.034409,
     "end_time": "2025-11-30T17:39:10.821619",
     "exception": false,
     "start_time": "2025-11-30T17:39:10.787210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"23f3001910-t32025\"\n",
    "WANDB_ENTITY = \"23f3001910-indian-institute-of-technology-madras\"\n",
    "\n",
    "DEBERTA_ARTIFACTS = [\n",
    "    \"deberta_large_seed_42:v1\",\n",
    "    \"deberta_large_seed_2025:v0\",\n",
    "    \"deberta_large_seed_123:v0\",\n",
    "]\n",
    "\n",
    "ROBERTA_ARTIFACTS = [\n",
    "    \"deberta_large_seed_42:v2\",\n",
    "    \"deberta_large_seed_2025:v1\",\n",
    "    \"deberta_large_seed_123:v1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f6f031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:10.880438Z",
     "iopub.status.busy": "2025-11-30T17:39:10.880156Z",
     "iopub.status.idle": "2025-11-30T17:39:10.883443Z",
     "shell.execute_reply": "2025-11-30T17:39:10.882867Z"
    },
    "id": "EBOZGiYWs83D",
    "papermill": {
     "duration": 0.034624,
     "end_time": "2025-11-30T17:39:10.884413",
     "exception": false,
     "start_time": "2025-11-30T17:39:10.849789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBERTA_WEIGHT = 0.45\n",
    "ROBERTA_WEIGHT = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c95f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:10.942800Z",
     "iopub.status.busy": "2025-11-30T17:39:10.942576Z",
     "iopub.status.idle": "2025-11-30T17:39:11.100282Z",
     "shell.execute_reply": "2025-11-30T17:39:11.099468Z"
    },
    "id": "Bq4kB0sXy91G",
    "papermill": {
     "duration": 0.189173,
     "end_time": "2025-11-30T17:39:11.101697",
     "exception": false,
     "start_time": "2025-11-30T17:39:10.912524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VAL_PATH = \"/kaggle/input/mydatasetfordl/augmented_train.csv\"\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "\n",
    "\n",
    "\n",
    "TEST_PATH = \"/kaggle/input/mydatasetfordl/test_clean.csv\"\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "test_texts = test[\"text\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99443aae",
   "metadata": {
    "id": "Jh2kyiBXtI-B",
    "papermill": {
     "duration": 0.028306,
     "end_time": "2025-11-30T17:39:11.159102",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.130796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a636fade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:11.215786Z",
     "iopub.status.busy": "2025-11-30T17:39:11.215522Z",
     "iopub.status.idle": "2025-11-30T17:39:11.220742Z",
     "shell.execute_reply": "2025-11-30T17:39:11.220199Z"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1764522794902,
     "user": {
      "displayName": "Shipra",
      "userId": "05727147388801096449"
     },
     "user_tz": -330
    },
    "id": "Sz6VyPDCtMZg",
    "papermill": {
     "duration": 0.034954,
     "end_time": "2025-11-30T17:39:11.221825",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.186871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_wandb_artifacts(artifact_names, model_type=\"DeBERTa\"):\n",
    "\n",
    "    local_paths = []\n",
    "\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=WANDB_PROJECT,\n",
    "        entity=WANDB_ENTITY,\n",
    "        job_type=\"inference\",\n",
    "        name=f\"ensemble_{model_type.lower()}\",\n",
    "    )\n",
    "\n",
    "    for idx, artifact_name in enumerate(artifact_names):\n",
    "        try:\n",
    "\n",
    "            artifact = run.use_artifact(artifact_name, type='model')\n",
    "            artifact_dir = artifact.download()\n",
    "\n",
    "            local_paths.append(artifact_dir)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            try:\n",
    "                artifact_name_no_version = artifact_name.split(':')[0]\n",
    "                artifact = run.use_artifact(f\"{artifact_name_no_version}:latest\", type='model')\n",
    "                artifact_dir = artifact.download()\n",
    "                local_paths.append(artifact_dir)\n",
    "            except Exception as e2:\n",
    "\n",
    "                continue\n",
    "\n",
    "    wandb.finish()\n",
    "    return local_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57183a9a",
   "metadata": {
    "id": "Acda5rZXttd6",
    "papermill": {
     "duration": 0.027257,
     "end_time": "2025-11-30T17:39:11.276989",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.249732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07c26f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:11.333831Z",
     "iopub.status.busy": "2025-11-30T17:39:11.333601Z",
     "iopub.status.idle": "2025-11-30T17:39:11.338396Z",
     "shell.execute_reply": "2025-11-30T17:39:11.337715Z"
    },
    "id": "Q0JMwW8btu6_",
    "papermill": {
     "duration": 0.034514,
     "end_time": "2025-11-30T17:39:11.339602",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.305088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_optimal_thresholds(val_probs, val_labels):\n",
    "    thresholds = {}\n",
    "\n",
    "\n",
    "    for i, label in enumerate(LABEL_COLS):\n",
    "        best_f1 = 0\n",
    "        best_thresh = 0.5\n",
    "\n",
    "        for thresh in np.arange(0.2, 0.8, 0.05):\n",
    "            preds = (val_probs[:, i] >= thresh).astype(int)\n",
    "            f1 = f1_score(val_labels[:, i], preds, zero_division=0)\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_thresh = thresh\n",
    "\n",
    "        thresholds[label] = best_thresh\n",
    "        print(f\"{label:10s}: threshold={best_thresh:.2f}, F1={best_f1:.4f}\")\n",
    "\n",
    "\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373f89b",
   "metadata": {
    "id": "8fGrp6FetzQ2",
    "papermill": {
     "duration": 0.027625,
     "end_time": "2025-11-30T17:39:11.394893",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.367268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3ee42fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:11.451651Z",
     "iopub.status.busy": "2025-11-30T17:39:11.451388Z",
     "iopub.status.idle": "2025-11-30T17:39:11.455415Z",
     "shell.execute_reply": "2025-11-30T17:39:11.454844Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1764523628574,
     "user": {
      "displayName": "Shipra",
      "userId": "05727147388801096449"
     },
     "user_tz": -330
    },
    "id": "V7aW-IHKt0-g",
    "papermill": {
     "duration": 0.033514,
     "end_time": "2025-11-30T17:39:11.456526",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.423012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_model_files(artifact_dir):\n",
    "    if os.path.exists(os.path.join(artifact_dir, \"config.json\")):\n",
    "        return artifact_dir\n",
    "\n",
    "    for item in os.listdir(artifact_dir):\n",
    "        subdir = os.path.join(artifact_dir, item)\n",
    "        if os.path.isdir(subdir):\n",
    "            if os.path.exists(os.path.join(subdir, \"config.json\")):\n",
    "                return subdir\n",
    "\n",
    "    return artifact_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c205c15",
   "metadata": {
    "id": "jq2SZ5LGwslI",
    "papermill": {
     "duration": 0.02727,
     "end_time": "2025-11-30T17:39:11.511373",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.484103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a11e8c3",
   "metadata": {
    "id": "w-o3ZUSRwtEA",
    "papermill": {
     "duration": 0.027375,
     "end_time": "2025-11-30T17:39:11.566612",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.539237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5dd22b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:11.622532Z",
     "iopub.status.busy": "2025-11-30T17:39:11.622255Z",
     "iopub.status.idle": "2025-11-30T17:39:11.629561Z",
     "shell.execute_reply": "2025-11-30T17:39:11.628972Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1764523630697,
     "user": {
      "displayName": "Shipra",
      "userId": "05727147388801096449"
     },
     "user_tz": -330
    },
    "id": "5y7xxBMbwuDm",
    "papermill": {
     "duration": 0.036874,
     "end_time": "2025-11-30T17:39:11.630829",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.593955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_predictions(model_paths, texts, model_type=\"DeBERTa\"):\n",
    "\n",
    "    all_preds = []\n",
    "\n",
    "\n",
    "    print(f\"Generating {model_type} Predictions\")\n",
    "\n",
    "\n",
    "    for idx, model_path in enumerate(model_paths):\n",
    "\n",
    "        try:\n",
    "            actual_model_path = find_model_files(model_path)\n",
    "\n",
    "\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\n",
    "                actual_model_path,\n",
    "                local_files_only=True,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                actual_model_path,\n",
    "                local_files_only=True,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            model.to(DEVICE)\n",
    "            model.eval()\n",
    "\n",
    "            batch_preds = []\n",
    "            BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "            for i in range(0, len(texts), BATCH_SIZE):\n",
    "                batch_texts = texts[i:i+BATCH_SIZE]\n",
    "                inputs = tokenizer(\n",
    "                    batch_texts,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=512\n",
    "                ).to(DEVICE)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "                    batch_preds.extend(probs)\n",
    "\n",
    "                if (i // BATCH_SIZE + 1) % 10 == 0:\n",
    "                    print(f\"    Processed {i + len(batch_texts)}/{len(texts)} texts\")\n",
    "\n",
    "            all_preds.append(np.array(batch_preds))\n",
    "\n",
    "            # Free memory\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    if len(all_preds) == 0:\n",
    "        raise ValueError(f\"No {model_type} models were successfully loaded!\")\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "\n",
    "    return avg_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7266fc0e",
   "metadata": {
    "id": "3OWezhmmxZXu",
    "papermill": {
     "duration": 0.027709,
     "end_time": "2025-11-30T17:39:11.687618",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.659909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d21f6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:11.743585Z",
     "iopub.status.busy": "2025-11-30T17:39:11.743336Z",
     "iopub.status.idle": "2025-11-30T17:39:11.772176Z",
     "shell.execute_reply": "2025-11-30T17:39:11.771476Z"
    },
    "id": "h81Znxa1yAZD",
    "papermill": {
     "duration": 0.05846,
     "end_time": "2025-11-30T17:39:11.773414",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.714954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "_, temp_df = train_test_split(val_df, test_size=0.2, random_state=42)\n",
    "val_df, _ = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "val_texts = val_df[\"text\"].astype(str).tolist()\n",
    "val_labels = val_df[LABEL_COLS].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "508131a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:39:11.835367Z",
     "iopub.status.busy": "2025-11-30T17:39:11.834736Z",
     "iopub.status.idle": "2025-11-30T17:41:04.704277Z",
     "shell.execute_reply": "2025-11-30T17:41:04.703563Z"
    },
    "papermill": {
     "duration": 112.902352,
     "end_time": "2025-11-30T17:41:04.705692",
     "exception": false,
     "start_time": "2025-11-30T17:39:11.803340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.20.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251130_173911-50ah5nf2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mensemble_deberta\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/50ah5nf2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact deberta_large_seed_42:v1, 1670.31MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:16.8 (99.3MB/s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact deberta_large_seed_2025:v0, 1670.31MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:23.1 (72.3MB/s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact deberta_large_seed_123:v0, 1670.31MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:19.6 (85.3MB/s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mensemble_deberta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/50ah5nf2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251130_173911-50ah5nf2/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.20.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20251130_174015-a5r43ufo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mensemble_roberta\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/a5r43ufo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact deberta_large_seed_42:v2, 1360.25MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:15.8 (86.4MB/s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact deberta_large_seed_2025:v1, 1360.25MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:15.1 (90.1MB/s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact deberta_large_seed_123:v1, 1360.25MB. 8 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   8 of 8 files downloaded.  \n",
      "Done. 0:0:14.7 (92.6MB/s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mensemble_roberta\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025/runs/a5r43ufo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/23f3001910-indian-institute-of-technology-madras/23f3001910-t32025\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251130_174015-a5r43ufo/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "deberta_paths = download_wandb_artifacts(DEBERTA_ARTIFACTS, \"DeBERTa\")\n",
    "roberta_paths = download_wandb_artifacts(ROBERTA_ARTIFACTS, \"RoBERTa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e6cc3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:41:04.769012Z",
     "iopub.status.busy": "2025-11-30T17:41:04.768763Z",
     "iopub.status.idle": "2025-11-30T17:42:42.277142Z",
     "shell.execute_reply": "2025-11-30T17:42:42.276354Z"
    },
    "id": "gz54JCP4yFsn",
    "papermill": {
     "duration": 97.540795,
     "end_time": "2025-11-30T17:42:42.278383",
     "exception": false,
     "start_time": "2025-11-30T17:41:04.737588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DeBERTa Predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 17:41:10.648693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764524470.832847      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764524470.890077      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed 160/1563 texts\n",
      "    Processed 320/1563 texts\n",
      "    Processed 480/1563 texts\n",
      "    Processed 640/1563 texts\n",
      "    Processed 800/1563 texts\n",
      "    Processed 960/1563 texts\n",
      "    Processed 1120/1563 texts\n",
      "    Processed 1280/1563 texts\n",
      "    Processed 1440/1563 texts\n",
      "    Processed 160/1563 texts\n",
      "    Processed 320/1563 texts\n",
      "    Processed 480/1563 texts\n",
      "    Processed 640/1563 texts\n",
      "    Processed 800/1563 texts\n",
      "    Processed 960/1563 texts\n",
      "    Processed 1120/1563 texts\n",
      "    Processed 1280/1563 texts\n",
      "    Processed 1440/1563 texts\n",
      "    Processed 160/1563 texts\n",
      "    Processed 320/1563 texts\n",
      "    Processed 480/1563 texts\n",
      "    Processed 640/1563 texts\n",
      "    Processed 800/1563 texts\n",
      "    Processed 960/1563 texts\n",
      "    Processed 1120/1563 texts\n",
      "    Processed 1280/1563 texts\n",
      "    Processed 1440/1563 texts\n",
      "Generating RoBERTa Predictions\n",
      "    Processed 160/1563 texts\n",
      "    Processed 320/1563 texts\n",
      "    Processed 480/1563 texts\n",
      "    Processed 640/1563 texts\n",
      "    Processed 800/1563 texts\n",
      "    Processed 960/1563 texts\n",
      "    Processed 1120/1563 texts\n",
      "    Processed 1280/1563 texts\n",
      "    Processed 1440/1563 texts\n",
      "    Processed 160/1563 texts\n",
      "    Processed 320/1563 texts\n",
      "    Processed 480/1563 texts\n",
      "    Processed 640/1563 texts\n",
      "    Processed 800/1563 texts\n",
      "    Processed 960/1563 texts\n",
      "    Processed 1120/1563 texts\n",
      "    Processed 1280/1563 texts\n",
      "    Processed 1440/1563 texts\n",
      "    Processed 160/1563 texts\n",
      "    Processed 320/1563 texts\n",
      "    Processed 480/1563 texts\n",
      "    Processed 640/1563 texts\n",
      "    Processed 800/1563 texts\n",
      "    Processed 960/1563 texts\n",
      "    Processed 1120/1563 texts\n",
      "    Processed 1280/1563 texts\n",
      "    Processed 1440/1563 texts\n",
      "anger     : threshold=0.35, F1=0.8506\n",
      "joy       : threshold=0.45, F1=0.8593\n",
      "fear      : threshold=0.50, F1=0.8815\n",
      "surprise  : threshold=0.35, F1=0.8499\n",
      "sadness   : threshold=0.45, F1=0.8445\n"
     ]
    }
   ],
   "source": [
    "deberta_val_probs = get_model_predictions(deberta_paths, val_texts, \"DeBERTa\")\n",
    "roberta_val_probs = get_model_predictions(roberta_paths, val_texts, \"RoBERTa\")\n",
    "\n",
    "\n",
    "ensemble_val_probs = (\n",
    "    DEBERTA_WEIGHT * deberta_val_probs +\n",
    "    ROBERTA_WEIGHT * roberta_val_probs\n",
    ")\n",
    "\n",
    "# Find optimal thresholds\n",
    "optimal_thresholds = find_optimal_thresholds(ensemble_val_probs, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f403d3cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:42:42.346538Z",
     "iopub.status.busy": "2025-11-30T17:42:42.345666Z",
     "iopub.status.idle": "2025-11-30T17:42:42.361445Z",
     "shell.execute_reply": "2025-11-30T17:42:42.360724Z"
    },
    "id": "9GIbzACMyNuv",
    "papermill": {
     "duration": 0.050684,
     "end_time": "2025-11-30T17:42:42.362634",
     "exception": false,
     "start_time": "2025-11-30T17:42:42.311950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.8572\n",
      "anger     : 0.8506\n",
      "joy       : 0.8593\n",
      "fear      : 0.8815\n",
      "surprise  : 0.8499\n",
      "sadness   : 0.8445\n"
     ]
    }
   ],
   "source": [
    "val_preds = np.zeros_like(ensemble_val_probs)\n",
    "for i, label in enumerate(LABEL_COLS):\n",
    "    val_preds[:, i] = (ensemble_val_probs[:, i] >= optimal_thresholds[label]).astype(int)\n",
    "\n",
    "val_macro_f1 = f1_score(val_labels, val_preds, average=\"macro\", zero_division=0)\n",
    "val_per_label_f1 = f1_score(val_labels, val_preds, average=None, zero_division=0)\n",
    "\n",
    "\n",
    "print(f\"Macro F1: {val_macro_f1:.4f}\")\n",
    "for label, f1 in zip(LABEL_COLS, val_per_label_f1):\n",
    "    print(f\"{label:10s}: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790ab717",
   "metadata": {
    "id": "5aytHm32ydvf",
    "papermill": {
     "duration": 0.034616,
     "end_time": "2025-11-30T17:42:42.431795",
     "exception": false,
     "start_time": "2025-11-30T17:42:42.397179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53af23a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:42:42.504737Z",
     "iopub.status.busy": "2025-11-30T17:42:42.503992Z",
     "iopub.status.idle": "2025-11-30T17:43:51.640794Z",
     "shell.execute_reply": "2025-11-30T17:43:51.640090Z"
    },
    "id": "uWARvehJyinQ",
    "papermill": {
     "duration": 69.17462,
     "end_time": "2025-11-30T17:43:51.642244",
     "exception": false,
     "start_time": "2025-11-30T17:42:42.467624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DeBERTa Predictions\n",
      "    Processed 160/1707 texts\n",
      "    Processed 320/1707 texts\n",
      "    Processed 480/1707 texts\n",
      "    Processed 640/1707 texts\n",
      "    Processed 800/1707 texts\n",
      "    Processed 960/1707 texts\n",
      "    Processed 1120/1707 texts\n",
      "    Processed 1280/1707 texts\n",
      "    Processed 1440/1707 texts\n",
      "    Processed 1600/1707 texts\n",
      "    Processed 160/1707 texts\n",
      "    Processed 320/1707 texts\n",
      "    Processed 480/1707 texts\n",
      "    Processed 640/1707 texts\n",
      "    Processed 800/1707 texts\n",
      "    Processed 960/1707 texts\n",
      "    Processed 1120/1707 texts\n",
      "    Processed 1280/1707 texts\n",
      "    Processed 1440/1707 texts\n",
      "    Processed 1600/1707 texts\n",
      "    Processed 160/1707 texts\n",
      "    Processed 320/1707 texts\n",
      "    Processed 480/1707 texts\n",
      "    Processed 640/1707 texts\n",
      "    Processed 800/1707 texts\n",
      "    Processed 960/1707 texts\n",
      "    Processed 1120/1707 texts\n",
      "    Processed 1280/1707 texts\n",
      "    Processed 1440/1707 texts\n",
      "    Processed 1600/1707 texts\n",
      "Generating RoBERTa Predictions\n",
      "    Processed 160/1707 texts\n",
      "    Processed 320/1707 texts\n",
      "    Processed 480/1707 texts\n",
      "    Processed 640/1707 texts\n",
      "    Processed 800/1707 texts\n",
      "    Processed 960/1707 texts\n",
      "    Processed 1120/1707 texts\n",
      "    Processed 1280/1707 texts\n",
      "    Processed 1440/1707 texts\n",
      "    Processed 1600/1707 texts\n",
      "    Processed 160/1707 texts\n",
      "    Processed 320/1707 texts\n",
      "    Processed 480/1707 texts\n",
      "    Processed 640/1707 texts\n",
      "    Processed 800/1707 texts\n",
      "    Processed 960/1707 texts\n",
      "    Processed 1120/1707 texts\n",
      "    Processed 1280/1707 texts\n",
      "    Processed 1440/1707 texts\n",
      "    Processed 1600/1707 texts\n",
      "    Processed 160/1707 texts\n",
      "    Processed 320/1707 texts\n",
      "    Processed 480/1707 texts\n",
      "    Processed 640/1707 texts\n",
      "    Processed 800/1707 texts\n",
      "    Processed 960/1707 texts\n",
      "    Processed 1120/1707 texts\n",
      "    Processed 1280/1707 texts\n",
      "    Processed 1440/1707 texts\n",
      "    Processed 1600/1707 texts\n"
     ]
    }
   ],
   "source": [
    "deberta_test_probs = get_model_predictions(deberta_paths, test_texts, \"DeBERTa\")\n",
    "roberta_test_probs = get_model_predictions(roberta_paths, test_texts, \"RoBERTa\")\n",
    "\n",
    "# Weighted ensemble\n",
    "ensemble_test_probs = (\n",
    "    DEBERTA_WEIGHT * deberta_test_probs +\n",
    "    ROBERTA_WEIGHT * roberta_test_probs\n",
    ")\n",
    "\n",
    "# Apply optimal thresholds\n",
    "final_preds = np.zeros_like(ensemble_test_probs)\n",
    "for i, label in enumerate(LABEL_COLS):\n",
    "    final_preds[:, i] = (ensemble_test_probs[:, i] >= optimal_thresholds[label]).astype(int)\n",
    "\n",
    "# Create submission\n",
    "for i, label in enumerate(LABEL_COLS):\n",
    "    test[label] = final_preds[:, i].astype(int)\n",
    "\n",
    "columns_to_keep = ['id', 'anger', 'fear', 'joy', 'sadness', 'surprise']\n",
    "test = test[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40991388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:43:51.717000Z",
     "iopub.status.busy": "2025-11-30T17:43:51.716481Z",
     "iopub.status.idle": "2025-11-30T17:43:51.734250Z",
     "shell.execute_reply": "2025-11-30T17:43:51.733545Z"
    },
    "id": "n0GkBJtQyo7J",
    "papermill": {
     "duration": 0.054731,
     "end_time": "2025-11-30T17:43:51.735376",
     "exception": false,
     "start_time": "2025-11-30T17:43:51.680645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  anger  fear  joy  sadness  surprise\n",
       "0   0      1     1    0        0         0\n",
       "1   1      0     0    0        0         0\n",
       "2   2      1     1    0        0         0\n",
       "3   3      0     1    0        0         0\n",
       "4   4      0     1    0        0         1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee1d5024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T17:43:51.809812Z",
     "iopub.status.busy": "2025-11-30T17:43:51.809614Z",
     "iopub.status.idle": "2025-11-30T17:43:51.820430Z",
     "shell.execute_reply": "2025-11-30T17:43:51.819692Z"
    },
    "id": "hdldvhCUyxPG",
    "papermill": {
     "duration": 0.049464,
     "end_time": "2025-11-30T17:43:51.821751",
     "exception": false,
     "start_time": "2025-11-30T17:43:51.772287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved\n"
     ]
    }
   ],
   "source": [
    "# Save submission\n",
    "test.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission saved\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyONU0YdDQhlTwDBB3FFOZY1",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13800781,
     "sourceId": 115439,
     "sourceType": "competition"
    },
    {
     "datasetId": 8746680,
     "sourceId": 13745937,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 397.461097,
   "end_time": "2025-11-30T17:43:54.794131",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T17:37:17.333034",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
